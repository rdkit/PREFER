{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the small data experiments and comparison with the FS-Mol results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can be used to analyzed results obtained by running the run_PREFER_smalldata_example.ipynb notebook and to compare such results with the FS-Mol results, as described [here](https://github.com/microsoft/FS-Mol). Before running the cells, please download the results of the FS-Mol paper (.csv files) stored [here](https://github.com/microsoft/FS-Mol/tree/main/baselines)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WARNING:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this notebook, please \n",
    "1) use the prefer-environment\n",
    "2) unpack the git submodules within the PREFER repo as described in the README.txt\n",
    "3) Change the config files as described in the README.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "%load_ext autoreload\n",
    "# path to the main directory\n",
    "path_to_PREFER = 'path_to/PREFER/'\n",
    "# path to submodules\n",
    "path_to_cddd = 'path_to/cddd/'\n",
    "path_to_moler = 'path_to/molecule-generation/'\n",
    "sys.path.append(path_to_PREFER)\n",
    "sys.path.append(path_to_cddd)\n",
    "sys.path.append(path_to_moler)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from prefer.utils.filtering import *\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from prefer.utils.post_processing_and_optimization_helpers import create_heat_map\n",
    "from prefer.utils.automation import merge_table_metrics, data_preparation, generate_molecular_representations, run, create_comparison_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTILS FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only the following assays have been used for comparison\n",
    "common_assays = ['CHEMBL1243967',\n",
    " 'CHEMBL1613800',\n",
    " 'CHEMBL1613898',\n",
    " 'CHEMBL1614027',\n",
    " 'CHEMBL1614503',\n",
    " 'CHEMBL1738395',\n",
    " 'CHEMBL1738579',\n",
    " 'CHEMBL1963715',\n",
    " 'CHEMBL1963756',\n",
    " 'CHEMBL1963824',\n",
    " 'CHEMBL1963827',\n",
    " 'CHEMBL1963969',\n",
    " 'CHEMBL2218957',\n",
    " 'CHEMBL2218989',\n",
    " 'CHEMBL2219050',\n",
    " 'CHEMBL2219070',\n",
    " 'CHEMBL2219102',\n",
    " 'CHEMBL2219104',\n",
    " 'CHEMBL2219113',\n",
    " 'CHEMBL2219115',\n",
    " 'CHEMBL2219146',\n",
    " 'CHEMBL2219159',\n",
    " 'CHEMBL2219180',\n",
    " 'CHEMBL2219194',\n",
    " 'CHEMBL2219203',\n",
    " 'CHEMBL2219211',\n",
    " 'CHEMBL2219242',\n",
    " 'CHEMBL2219244',\n",
    " 'CHEMBL2219283',\n",
    " 'CHEMBL2219297',\n",
    " 'CHEMBL2219308',\n",
    " 'CHEMBL2219363',\n",
    " 'CHEMBL3214944',\n",
    " 'CHEMBL3431932',\n",
    " 'CHEMBL3431933',\n",
    " 'CHEMBL3706128',\n",
    " 'CHEMBL3707783',\n",
    " 'CHEMBL641707',\n",
    " 'CHEMBL657032',\n",
    " 'CHEMBL819742']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "path_to_dfs = 'path_to/fs-mol/csv_files/' # path to the csv files converted from the zip files with extract_zipped_files.ipynb notebook\n",
    "path_to_df_list = os.listdir(path_to_dfs)\n",
    "dimensions = []\n",
    "ratios = []\n",
    "for common_assay in common_assays:\n",
    "    df_tmp = pd.read_csv(path_to_dfs+common_assay+'.csv')\n",
    "    dimensions.append(df_tmp.shape[0])\n",
    "    ratios.append(np.round(df_tmp.Property.sum()/df_tmp.shape[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(dimensions, bins='auto')\n",
    "plt.title('Data dimensions distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(ratios, bins='auto')\n",
    "plt.title('Data classes ratio distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# go into merged and mean\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "merged_mean = dict()\n",
    "merged_std = dict()\n",
    "limit_defs = ['16', '32', '64', '128', '256'] # number of samples used inthe training set\n",
    "\n",
    "path_to_mergeds_dict = {}\n",
    "\n",
    "for limit_def in limit_defs:\n",
    "    df_concat = pd.DataFrame()\n",
    "    num_folder = 0\n",
    "    path_to_mergeds_list = []\n",
    "    file_name_list = []\n",
    "    path_to_mergeds = os.listdir(f'./merged_folder_limit_def_{limit_def}')\n",
    "    for merged in path_to_mergeds:\n",
    "        file_name = merged.split('_')[-1]\n",
    "        file_name = file_name.split('.')[0]\n",
    "        file_name_list.append(file_name)\n",
    "\n",
    "        if((not merged.startswith('.')) and (file_name in common_assays)):\n",
    "            num_folder = num_folder +1\n",
    "            df = pd.read_csv(f'./merged_folder_limit_def_{limit_def}/{merged}')\n",
    "            df = df.iloc[3:]\n",
    "            df_concat = pd.concat((df, df_concat))\n",
    "        else:\n",
    "            continue\n",
    "    path_to_mergeds_list= path_to_mergeds_list+file_name_list\n",
    "        #collect all the deltaAUPRC for each merged table\n",
    "    df_concat.index = df_concat.Metrics\n",
    "    df_concat.drop(columns = ['Metrics'], inplace = True)\n",
    "    df_concat = df_concat.astype(float)\n",
    "    by_row_index = df_concat.groupby(df_concat.index)\n",
    "    path_to_mergeds_dict[limit_def] = path_to_mergeds_list\n",
    "    merged_mean[limit_def] = by_row_index.mean() \n",
    "    merged_std[limit_def] = by_row_index.std()/np.sqrt(num_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dict_mean = dict()\n",
    "tmp_dict_std = dict()\n",
    "for limit_def in limit_defs:\n",
    "    \n",
    "    _, tmp_dict_mean[limit_def] = create_comparison_table(merged_mean[limit_def], metric_classification = \"deltaAUPRC\")\n",
    "    _, tmp_dict_std[limit_def] = create_comparison_table(merged_std[limit_def], metric_classification = \"deltaAUPRC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# collect results for comparison with baseline\n",
    "# save\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# define the name of the directory to be created\n",
    "path = \"delta_performance_folder\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % path)\n",
    "    \n",
    "best_representation = None \n",
    "exp_names = []\n",
    "best_metric_std = None\n",
    "metric = 'deltaAUPRC'\n",
    "delta_performance = dict()\n",
    "for limit_def in limit_defs:\n",
    "    delta_performance[limit_def] = dict()\n",
    "    for index, exp_name in enumerate(tmp_dict_mean[limit_def].keys()):\n",
    "        exp_names.append(exp_name)\n",
    "\n",
    "        best_metric_value = -1000\n",
    "        for representation in tmp_dict_mean[limit_def][exp_name].keys():\n",
    "            current_metric_value = tmp_dict_mean[limit_def][exp_name][representation][exp_name]\n",
    "            current_metric_std = tmp_dict_std[limit_def][exp_name][representation][exp_name]\n",
    "            if current_metric_value>best_metric_value:\n",
    "                best_metric_value = current_metric_value\n",
    "                best_metric_std = current_metric_std\n",
    "                best_representation = representation\n",
    "\n",
    "        delta_performance[limit_def]['experiment_name'] = exp_name\n",
    "        delta_performance[limit_def]['metric'] = metric\n",
    "        delta_performance[limit_def]['prefer_model_performance_mean'] = best_metric_value\n",
    "        delta_performance[limit_def]['prefer_model_performance_std'] = best_metric_std\n",
    "        delta_performance[limit_def]['prefer_model_representation'] = best_representation\n",
    "\n",
    "    \n",
    "with open(f'{path}/delta_performance_ALL.pkl', 'wb') as f:\n",
    "    pickle.dump(delta_performance, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "vect_means = [delta_performance['16']['prefer_model_performance_mean'], \n",
    "              delta_performance['32']['prefer_model_performance_mean'],\n",
    "              delta_performance['64']['prefer_model_performance_mean'], \n",
    "              delta_performance['128']['prefer_model_performance_mean'], \n",
    "              delta_performance['256']['prefer_model_performance_mean']]\n",
    "\n",
    "vect_stds = [delta_performance['16']['prefer_model_performance_std'], \n",
    "              delta_performance['32']['prefer_model_performance_std'],\n",
    "              delta_performance['64']['prefer_model_performance_std'], \n",
    "              delta_performance['128']['prefer_model_performance_std'], \n",
    "              delta_performance['256']['prefer_model_performance_std']]\n",
    "model_name = ['16', '32', '64', '128', '256']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams[\"figure.figsize\"] = (8,5.5)\n",
    "plt.errorbar(range(0, 5), vect_means,\n",
    "                 yerr=vect_stds, fmt='', linewidth=3, label=model_name)  # To draw legend\n",
    "\n",
    "locs, labels = plt.xticks()  # Get the current locations and labels.\n",
    "plt.xticks(np.arange(len(model_name)), list(model_name))\n",
    "plt.grid(color = 'grey', linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "#plt.legend(bbox_to_anchor=(1.8, 0.2),loc=\"upper right\")\n",
    "plt.ylabel('∆AUPRC', fontdict=None)\n",
    "plt.ylim(0,0.4)\n",
    "plt.xlabel('Training size', fontdict=None)\n",
    "plt.savefig(f'small_data_performances2.png', bbox_inches='tight', transparent=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing PREFER to FS-MOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the cells, please download the results of the FS-Mol paper (.csv files) stored [here](https://github.com/microsoft/FS-Mol/tree/main/baselines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "limit_defs = ['16', '32', '64', '128', '256']\n",
    "\n",
    "path_to_fsmol_res = 'path_to/fs-results/' # path to the FS-Mol results as reported in the git repo\n",
    "path_to_fsresults = os.listdir(path_to_fsmol_res)\n",
    "vect_list_means = dict()\n",
    "vect_list_stds = dict()\n",
    "for res in path_to_fsresults:\n",
    "    name = res.replace('.csv', '')\n",
    "    vect_list_means[name] = [] # for each limit def one elem\n",
    "    vect_list_stds[name] = []\n",
    "    df = pd.read_csv(f'{path_to_fsmol_res}{res}')\n",
    "    for limit_def in limit_defs:\n",
    "        elems_per_assay_per_limit_def = []\n",
    "        for elem, fr_train in zip(df[f'{limit_def}_train'].values, df.fraction_positive_train.values):\n",
    "            if not isinstance(elem, float):\n",
    "                elem_converted = float(elem.split('+')[0])\n",
    "                elems_per_assay_per_limit_def.append(elem_converted-fr_train)\n",
    "        vect_list_means[name].append(np.mean(elems_per_assay_per_limit_def))\n",
    "        vect_list_stds[name].append(np.std(elems_per_assay_per_limit_def)/np.sqrt(len(elems_per_assay_per_limit_def)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "colors = sns.color_palette(\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams[\"figure.figsize\"] = (8,5.5)\n",
    "for index, key in enumerate(vect_list_means.keys()):\n",
    "    vect_means_sd = vect_list_means[key]\n",
    "    vect_stds_sd = vect_list_stds[key]\n",
    "    model_name_sd = limit_defs\n",
    "    plt.errorbar(range(0, 5), vect_means_sd,\n",
    "                     yerr=vect_stds_sd, fmt='', linewidth=3, label=key, color = colors[index], alpha = 0.7)  # To draw legend\n",
    "\n",
    "    locs, labels = plt.xticks()  # Get the current locations and labels.\n",
    "    plt.xticks(np.arange(len(model_name_sd)), list(model_name_sd))\n",
    "    plt.grid(color = 'grey', linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.5, 0.2),loc=\"upper right\")\n",
    "    \n",
    "plt.errorbar(range(0, 5), vect_means,\n",
    "                 yerr=vect_stds, fmt='', linewidth=3, label = 'PREFER', color = 'black')  # To draw legend\n",
    "plt.legend(bbox_to_anchor=(1.6, 0.2),loc=\"upper right\")\n",
    "plt.ylabel('∆AUPRC', fontdict=None)\n",
    "plt.ylim(0,0.4)\n",
    "plt.xlabel('Training size', fontdict=None)\n",
    "plt.savefig(f'PREFER4small_data_comparison.png', bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (prefer-env-released2)",
   "language": "python",
   "name": "prefer-env-released2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
